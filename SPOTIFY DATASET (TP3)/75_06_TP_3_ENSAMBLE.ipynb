{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TSaUPg1MDyOq_gGPpCiAUqkk7ZsZ7lbX",
      "authorship_tag": "ABX9TyMCfvMivO34GKN9Q41E1CHr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbarreto10/data-science-2022/blob/main/SPOTIFY%20DATASET%20(TP3)/75_06_TP_3_ENSAMBLE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LECTURA**"
      ],
      "metadata": {
        "id": "HM5WlTzT95CY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBNU80bI9T3L",
        "outputId": "bfdc1681-fe4a-47c0-abc9-47f09c595d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "stopwordsSpEn = set(stopwords.words('english')+stopwords.words('spanish'))\n",
        "sPunctuations = list(string.punctuation)\n",
        "sDigits = list(string.digits)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainDf = pd.read_parquet(\"/content/drive/MyDrive/tp3/train.parquet\")\n",
        "testDf = pd.read_parquet(\"/content/drive/MyDrive/tp3/test.parquet\")"
      ],
      "metadata": {
        "id": "vbaKtHRP97FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SPLIT**"
      ],
      "metadata": {
        "id": "rtiSut6F9-hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(3)\n",
        "artistList = trainDf.artist.unique().tolist()\n",
        "validationArtists = random.sample(artistList, int(0.2*len(artistList)))\n",
        "trainDf, valDf = trainDf.query(\"artist not in @validationArtists\"), trainDf.query(\"artist in @validationArtists\")"
      ],
      "metadata": {
        "id": "MvbXbx-u9-8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREPROCESAMIENTO**"
      ],
      "metadata": {
        "id": "ie4Cb1gN-DEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genreList = trainDf[\"genre\"].unique().tolist()"
      ],
      "metadata": {
        "id": "HcF7AWiV-DZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def str_type_count(x, tset):\n",
        "    words = x.split()\n",
        "    return len([s for s in words if s in tset])\n",
        "\n",
        "def digit_count(x):\n",
        "    return len([d for d in x if d in sDigits])\n",
        "\n",
        "def word_max(x):\n",
        "    words = word_tokenize(x)\n",
        "    return 0 if len(words)==0 else max([len(w) for w in words])\n",
        "\n",
        "def word_min(x):\n",
        "    words = word_tokenize(x)\n",
        "    return 0 if len(words)==0 else min([len(w) for w in words if w not in stopwordsSpEn])\n",
        "\n",
        "def word_mean(x):\n",
        "    words = word_tokenize(x)\n",
        "    return 0 if len(words)==0 else np.mean([len(w) for w in words])\n",
        "\n",
        "def sent_max(x):\n",
        "    sents = sent_tokenize(x)\n",
        "    return 0 if len(sents)==0 else max([len(s) for s in sents])\n",
        "\n",
        "def sent_min(x):\n",
        "    sents = sent_tokenize(x)\n",
        "    return 0 if len(sents)==0 else min([len(s) for s in sents])\n",
        "\n",
        "def sent_mean(x):\n",
        "    sents = sent_tokenize(x)\n",
        "    return 0 if len(sents)==0 else np.mean([len(s) for s in sents])\n",
        "\n",
        "def preprocess(df):\n",
        "    # ARREGLOS Y DROPEOS\n",
        "    try:\n",
        "        df[\"genre\"][df[df.genre == \"Children's Music\"].index[0]] = \"Children’s Music\"\n",
        "    except:\n",
        "        pass\n",
        "    df = df.drop(columns = [\"track_name\",\"did\",\"artist\",\"a_genres\",\"a_songs\"])\n",
        "\n",
        "    # IMPUTACIÓN DE NULOS\n",
        "    s_labelMean = df[\"s-label\"].mean()\n",
        "    df.lyric = df.lyric.fillna(\"\").astype(str)\n",
        "    df.language = df.language.map(lambda x: \"ot\" if type(x)==type(None) else x)\n",
        "    df[\"s-label\"] = df[\"s-label\"].fillna(s_labelMean)\n",
        "    df[\"mode\"] = df[\"mode\"].map(lambda m: int(m==\"Major\"))\n",
        "\n",
        "    # CREACIÓN DE FEATURES A PARTIR DE LAS LYRICS\n",
        "    df[\"lyricCharCount\"] = df.lyric.map(len)\n",
        "    df[\"lyricWordCount\"] = df.lyric.map(lambda x: len(word_tokenize(x)))\n",
        "    df[\"lyricUniqueWordCount\"] = df.lyric.map(lambda x: len(set(x.split())))\n",
        "    df[\"lyricSentenceCount\"] = df.lyric.map(lambda x: len(sent_tokenize(x)))\n",
        "    df[\"lyricUniqueSentenceCount\"] = df.lyric.map(lambda x: len(set(sent_tokenize(x))))\n",
        "    df[\"lyricDigitCount\"] = df.lyric.map(digit_count)\n",
        "    df[\"lyricStopwordCount\"] = df.lyric.map(lambda x: str_type_count(x, stopwordsSpEn))\n",
        "    df[\"lyricPunctuationCount\"] = df.lyric.map(lambda x: str_type_count(x, sPunctuations))\n",
        "    df[\"lyricLongestWordLen\"] = df.lyric.map(word_max)\n",
        "    df[\"lyricShortestWordLen\"] = df.lyric.map(word_min)\n",
        "    df[\"lyricWordLenMean\"] = df.lyric.map(word_mean)\n",
        "    df[\"lyricLongestSentenceLen\"] = df.lyric.map(sent_max)\n",
        "    df[\"lyricShortestSentenceLen\"] = df.lyric.map(sent_min)\n",
        "    df[\"lyricSentenceLenMean\"] = df.lyric.map(sent_mean)\n",
        "\n",
        "    #Mean encoding de a_popularity respecto de categóricas\n",
        "    grpByLanguage = df.groupby([\"language\"]).mean()[\"a_popularity\"]\n",
        "    grpByKey = df.groupby([\"key\"]).mean()[\"a_popularity\"]\n",
        "    grpByTimeSignature = df.groupby([\"time_signature\"]).mean()[\"a_popularity\"]\n",
        "    grpByMode = df.groupby([\"mode\"]).mean()[\"a_popularity\"]\n",
        "    df[\"a_popularityMeanByLanguage\"] = df[\"language\"].map(lambda x: grpByLanguage[x])\n",
        "    df[\"a_popularityMeanByKey\"] = df[\"key\"].map(lambda x: grpByKey[x])\n",
        "    df[\"a_popularityMeanByTimeSignature\"] = df[\"time_signature\"].map(lambda x: grpByTimeSignature[x])\n",
        "    df[\"a_popularityMeanByMode\"] = df[\"mode\"].map(lambda x: grpByMode[x])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "SRL3QRvo-E9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDf = preprocess(trainDf)\n",
        "valDf = preprocess(valDf)\n",
        "testDf = preprocess(testDf)"
      ],
      "metadata": {
        "id": "AwigFiIC-E2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ESTANDARIZACIÓN Y ENCODING**"
      ],
      "metadata": {
        "id": "ArlXwptn-dCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized(column):\n",
        "    colStd = column.std()\n",
        "    return (column - column.mean()) / colStd if colStd!=0 else 0 * column"
      ],
      "metadata": {
        "id": "4xPy6w1G-c0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_df(df, featureList):\n",
        "    for f in featureList:\n",
        "        df[f] = normalized(df[f])\n",
        "    return df"
      ],
      "metadata": {
        "id": "FT8vYF7G-j5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def one_hot_encode(df, catCols):\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "    encoder.fit(df[catCols])\n",
        "    encFts = list(encoder.get_feature_names(catCols))\n",
        "    df[encFts] = encoder.transform(df[catCols])\n",
        "    return df"
      ],
      "metadata": {
        "id": "qNQA721v-lS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catCols = [\"language\",\"time_signature\",\"key\"]\n",
        "trainDf = one_hot_encode(trainDf, catCols)\n",
        "valDf = one_hot_encode(valDf, catCols)\n",
        "testDf = one_hot_encode(testDf, catCols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRX4HqpI-mqi",
        "outputId": "b69752f0-9210-4154-b347-da334c6bd331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "countIDF = CountVectorizer(lowercase=True, stop_words=stopwordsSpEn, max_features=50)\n",
        "countIDF.fit(trainDf.lyric)\n",
        "ftNames = [\"word\"+w.capitalize() for w in countIDF.get_feature_names_out()]\n",
        "\n",
        "for df in [trainDf, valDf, testDf]:\n",
        "    wordMatrix = countIDF.transform(df.lyric)\n",
        "    df[ftNames] = pd.DataFrame(wordMatrix.todense(), columns=ftNames, index=df.index)"
      ],
      "metadata": {
        "id": "GBFK6Pdg-oHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featureList = [f for f in trainDf if f not in [\"genre\",\"lyric\",\"language\",\"time_signature\",\"key\"]]"
      ],
      "metadata": {
        "id": "rvGB9wTs-pXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HAY CATEGORÍAS EN EL TRAIN_DF QUE NO ESTÁN EN EL VAL_DF O EN EL TEST_DF\n",
        "# COMO EL ONEHOTENCODING NO LAS CREO, LAS CREO COMO NULAS\n",
        "for f in featureList:\n",
        "    if f not in valDf:\n",
        "        valDf[f] = 0\n",
        "    if f not in testDf:\n",
        "        testDf[f] = 0"
      ],
      "metadata": {
        "id": "ewMQ6uAt-qgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDf = normalize_df(trainDf, featureList)\n",
        "valDf = normalize_df(valDf, featureList)\n",
        "testDf = normalize_df(testDf, featureList)"
      ],
      "metadata": {
        "id": "377ymbJp-rs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testDf = testDf.query(\"genre in @genreList\")\n",
        "valDf = valDf.query(\"genre in @genreList\")"
      ],
      "metadata": {
        "id": "3F_u9Ayg-s1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = trainDf[featureList], trainDf.genre.astype(str)\n",
        "X_test, y_test = testDf[featureList], testDf.genre.astype(str)\n",
        "X_val, y_val = valDf[featureList], valDf.genre.astype(str)"
      ],
      "metadata": {
        "id": "qBN2auXR-svR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELOS DE ML**"
      ],
      "metadata": {
        "id": "eL8Gp7orA6EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "from scipy.stats import loguniform\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "plg-CzpvA2T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbModel = XGBClassifier(eta=0.025, eval_metric='mlogloss', max_depth=9,\n",
        "              min_child_weight=7, objective='multi:softprob', seed=10,\n",
        "              subsample=0.825)\n",
        "xgbModel.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYg_h9-ZBUhq",
        "outputId": "fc69ca87-1baf-47fa-ade7-9274825a4d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(eta=0.025, eval_metric='mlogloss', max_depth=9,\n",
              "              min_child_weight=7, objective='multi:softprob', seed=10,\n",
              "              subsample=0.825)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN precisa clases numéricas, así que indexo los géneros\n",
        "classToNum = { g: genreList.index(g) for g in genreList }\n",
        "y_train_num = y_train.map(lambda x: classToNum[x])\n",
        "knnModel = KNeighborsClassifier(leaf_size=3, metric='manhattan', n_neighbors=13, p=1,\n",
        "                     weights='distance')\n",
        "knnModel.fit(X_train, y_train_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZRwMK5EDI2l",
        "outputId": "bff9c453-de78-4b73-b9c4-eed1235e666b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(leaf_size=3, metric='manhattan', n_neighbors=13, p=1,\n",
              "                     weights='distance')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ENSAMBLE DE MODELOS**"
      ],
      "metadata": {
        "id": "H5Sm6jLYCAdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgbValidProbs = xgbModel.predict_proba(X_val)\n",
        "knnValidProbs = knnModel.predict_proba(X_val)\n",
        "ensembleValScore = top_k_accuracy_score(y_val, (xgbValidProbs+knnValidProbs)/2, k=2, labels=xgbModel.classes_)"
      ],
      "metadata": {
        "id": "bA16F9mLvfIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Score del ensamble (validación): \" + str(ensembleValScore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJNySqG0_pCA",
        "outputId": "e5c805b0-45d8-4ecc-9da9-fe96825f1fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score del ensamble (validación): 0.43429844097995546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgbTestProbs = xgbModel.predict_proba(X_test)\n",
        "knnTestProbs = knnModel.predict_proba(X_test)\n",
        "ensembleTestScore = top_k_accuracy_score(y_test, (xgbTestProbs+knnTestProbs)/2, k=2, labels=xgbModel.classes_)"
      ],
      "metadata": {
        "id": "w-hdwA1qzX3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Score del ensamble (test): \" + str(ensembleTestScore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP_VpAAAAKQ3",
        "outputId": "e03c6676-5e70-4ed1-f9e5-fcdfaed5cfb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score del ensamble (test): 0.3957345971563981\n"
          ]
        }
      ]
    }
  ]
}